# 图解操作系统



## 第一章 硬件结构

### 1.1 CPU如何执行程序



### 1.2 存储结构金字塔

#### 1.2.1 存储结构分层

三层：

1. 寄存器
2.  Cache
3.  硬盘

前两个在CPU中，只能与相邻的存储设备交互。



#### 1.2.2 各种存储器

寄存器：很小，但是最快。

Cache：

1. L1：分为指令缓存和数据缓存
2. L2：
3. L3：直接与内存交互，各个CPU核心共有的。

内存：DRAM，比寄存器中的慢，但是较大。

硬盘：SSD/HDD，慢，大，断电可存储。

存储器分级的目的：



### 1.3 如何写出让CPU更快的代码



#### 1.3.1 CPU Cache数据结构和读取数据的过程

Cache读取的数据结构：数据行

读取数据的特点（顺序）：先从内存读入L3,再从L3往上读,依次读写.

直接映射：直接计算模.



#### 1.3.2 如何提高缓存命中率

缓存命中：如果访问的数据就在CPU寄存器中就叫缓存命中

提高数据缓存命中率：数据在数据寄存器中

提高指令缓存命中率：指令在指令寄存器中

1. 分支预测：如果很多选择都在为真或假，CPU会自己存储为真的值在寄存器中，以提高缓存命中率。

结论：先排序再遍历

提高多核CPU的缓存命中率：把线程绑定到某个核心上。



### 1.4 CPU缓存一致性

#### 1.4.1 写直达

数据在Cache：写入cache然后访问内存，并读取内存。

不在：从内存读入，然后返回给内存。

可见无论是否在cache内，都需要访问内存，十分缓慢



#### 1.4.2 写回

读取内存的条件:

1. 不在cache内
2.  该cache为脏数据

如果在缓存命中高的情况下,大部分时间CPU并不需要读写内存,此时写回会很快



#### 1.4.3 缓存一致性问题

写传播:在某个核心的cache内更新数据的时候，其他cache也同步更新数据

事务的串形化:CPU核心对数据的操作顺序，在其他CPU内也必须是一样的。





### 1.5 CPU如何执行任务的

CPU从内存中读入数据的单位：

伪共享问题：因为多个线程同时读写同一个cache line上的数据，导致CPU Cache失效的问题。

MESI协议：已共享，独占，失效，已修改的缩写，缓存行的四种状态。



解决伪共享问题的方法：





### 1.6 CPU如何选择线程的

CPU中有一个任务队列，如果任务过多就会排队，但我们可以通过调整任务的优先级来调整任务执行的顺序。

#### 1.6.1 任务和完全公平调度

实时任务：调度优先级范围：

普通任务：调度优先级范围：

完全公平调度：

vruntime：（只针对普通任务）

高权重任务vruntime在计算的情况下比低权重任务少。



#### 1.6.2 CPU运行队列

三种调度类：

- FIFO， 先进先出；
-  DEADLINE：为每个进程规定deadline，如果靠近deadline， 就先运行。
-  FAIR ：谁vruntime少，谁就先运行。

**所有的高优先级任务都可以抢占低优先级任务**



#### 1.6.3 调整优先级

nice值的范围：-20 ~ 19， 原因是nice值只对普通任务管用，对优先级高的任务没有什么用。



### 1.7 软中断

#### 1.7.1 中断

中断的概念：系统打断当前硬件设备的调用，然后启用中断处理程序

硬中断的概念：直接处理硬件请求，负责耗时短的工作。

​	特点：快速执行

软中断的概念：由内核触发，负责上半部未完成的工作。

​	特点：延迟执行



### 1.8 计算机中数据的表示

为什么用补码：方便二进制加减法，否则结果错误；

为什么0.1+0.2不等于0.3：0.1转换为2进制的时候是一个无限循环的数，无法准确表示；

#### 1.8.1 计算机存储小数

用的是浮点数来存储，表示小数点可以浮动。

32位：float单精度浮点数，64位：double双精度浮点数；



浮点数的存储方式：符号位＋指数（8位）+尾数（23位）【单指float】；



## 第二章 操作系统结构

### 2.1 内核

内核的四种能力：

1. 进程调度
2. 硬件通信
3. 提供系统调用 
4. 内存管理



内核态：运行在内核的应用程序；

用户态：运行在外部的应用程序；



## 第三章 内存管理

### 3.1 虚拟内存

虚拟内存地址：

物理内存地址：



#### 3.1.2 内存分段

每个程序可以分成多个段：数据，指令等等，然后每个段有段选择子（段号，用于在段表中找基地址）和段偏移量，基地址＋偏移量就就是物理地址。



**内存碎片**问题：因为地址不连续，所以会产生一些小的内存碎片，无法运行应用程序；

解决办法：**内存交换**（Swap空间），将内存不连续的地方调用到硬盘，然后从硬盘读入到内存，形成连续空间。

内存交换效率低的问题：频繁调用硬盘数据，会导致交换效率低，系统卡顿。（硬盘读写数据比内存慢）。



#### 3.1.3 内存分页

将物理地址按页划分，然后每次对某个页进行操作，并且不需要全部加载，用什么就从硬盘中读什么。



分页机制：

虚拟地址分为页号和页内偏移量，页表中根据虚拟页号查到物理页号，然后再到物理内存中查找。

问题：每个程序都需要虚拟内存，会导致虚拟页表占的内存很大；由此衍生出多级页表。

**多级页表**：在添加一个关于表的索引，然后对一二级页表访问，二级页表的内存根据局部性原理，不用的放在硬盘中，内存占用就很小，但是带来了时间效率的问题，于是引入了快表，**快表**的原理就是常用的就存储下来，直接内存中调用。



## 第四章 进程与线程

### 4.1 进程

并发和并行的区别：

并发是同一个cpu交替执行，而并行是指多个CPU执行不同的任务。

进程的状态：



进程状态转换：



### 4.2 PCB进程控制块

操作系统用PCB来唯一描述一个进程。

PCB中包含的信息： 

1. 进程描述信息：
2. 进程控制和管理信息：
3. 资源分配清单：
4. CPU相关信息：



#### 4.2.1 PCB组织的方式

数据结构：链表；

原因：为了方便创建和销毁（链表的插入和删除非常方便）。





### 4.3 进程的控制

#### 4.3.1 创建进程

分配进程标识号，分配空白PCB（PCB的数量有限，分配失败则创建失败）；

分配资源：如果资源被占用，就等待资源；

初始化PCB；

如果调度队列有空闲就插入到就绪队列。



#### 4.3.2 终止进程

1. 根据进程标识号查找进程；
2. 如果在执行，则立刻停止执行，然后将CPU资源分配给其他进程；
3. 如果还有子进程，也立刻结束子进程；
4. 释放所有资源，归还给父进程或者操作系统；
5. 将它从所在队列中删除；



#### 4.3.3 阻塞进程；

1. 根据进程标识号找到对应PCB；
2. 如果在运行，则立刻保护现场，转为阻塞态；
3. 将PCB插入到阻塞队列中；



#### 4.3.4 唤醒进程

1. 在阻塞队列中查找到对应PCB；
2. 然后将其状态置为就绪态，并从阻塞队列中移出；
3. 插入到就绪队列；



### 4.4 进程的上下文切换

各个进程共享CPU资源，从一个进程切换到另一个进程就是进程的上下文切换；

CPU上下文：

进程上下文切换进行的工作：



### 4.5 线程

可以并发运行并且可以共享相同地址空间的实体；线程就是进程的一条执行流程；

进程之间共享的部分：

不共享的部分:



#### 4.5.1 进程优缺点

优点：

1. 多个进程并发执行；
2. 进程间共享地址空间和文件等数据；
3. 一个进程中有多个线程

缺点：

1. 一个线程崩溃就会导致所有线程崩溃。

​	

### 4.6 进程与线程的比较

1. 进程是资源分配的单位，线程是CPU调度的单位；

2. 进程拥有完整的资源平台，而线程只独享必不可少的部分：寄存器和栈；

3. 线程也具有三种状态并且可以相互切换；

4. 线程可以减少并发执行的时间和空间：理由如下：

   1. 线程创建快；
   2. 销毁快；
   3. 切换快；
   4. 传递信息快；

   以上都基于线程共享地址信息和页表以及数据等数据。



### 4.7 线程的上下文切换

**线程是调度的基本单位，而进程是资源分配的基本单位**；

当一个进程只有一个线程的时候，可以认为进程就是线程，

但当一个进程有多个线程的时候，栈和寄存器是独享的，所以线程的上下文切换的时候也会切换这些东西。

但如果两个线程分属于不同的进程时候，就和进程切换没有什么区别了。



### 4.8 线程的实现

#### 4.8.1 用户线程

用户线程：用户线程基于用户态的线程管理库来调度分配，操作系统并不能看见TCB。

用户线程的优点：

1. 有用户态的函数库统一分配管理，可以在不支持操作系统的库上运行；
2. 用户线程的切换也由线程库函数来完成，无需切换用户态与内核态。

缺点：

1. 操作系统不参与线程的调度，如果一个线程阻塞，整个进程都会阻塞；
2. 一个线程开始运行后，其他线程无法抢占，因为调度cpu是操作系统的权力，但是用户态的线程管理无法进行这些操作。
3. 时间片分配给线程，每个线程得到的时间较少。



#### 4.8.2 内核线程

内核线程是由： 操作系统管理，TCB在：内核 ；

优点：

1.  一个线程被阻塞，不影响其他线程；
2.  每个线程获得更多的CPU时间；

缺点：

1.  内核同时管理线程和进程；
2.  系统开销较大；



### 4.9 调度

操作系统选择以一个进程在CPU中运行就是程序调度；

#### 4.9.1 调度时机：

1. 
2.  
3.  

#### 4.9.2 调度算法：

1. 非抢占式调度算法：
2. 抢占式调度算法 ：



### 4.10 调度算法

#### 先来先服务（FIFS）——非抢占

从 队列选择最先进入队列的进程，直到： 才继续从队列中选择下一个进程；

FCFS特点：



#### 短作业优先（SJF）——非抢占

优先选择运行时间最短的进程来运行；

SJF特点：



#### 高响应比优先（HRRN）

按优先权顺序进行调度：

**优先权算法：（等待时间+要求服务）/ 要求服务时间**



#### 时间片轮转算法（RR）

每个进程分配一个时间片，如果没有运行完就插入队尾；



#### 最高优先级调度算法（HPF）

抢占式：

非抢占式：



#### 多级反馈队列调度算法

多级：多个队列，每个队列优先级从高到低，并且优先级越高，时间片就越短；

反馈：如果有优先级更高的，则抢占调度；



### 4.11 进程间通信

#### 01 管道通信

优点：简单清晰；

缺点：效率低下，不适合进程间频繁的交互数据；

所有的数据都是在内核中交互，遵循先进先出原则；

生命周期和进程是同步的；



#### 02 消息队列

是保存在内核中的消息链表，发送端直接发到其中，接收端再到其中接收消息；

​	优点：效率高；

​	缺点：通信不及时，而且附件大小有限制；

消息队列不是较大数据的传输，并且在通信过程中，存在用户态与内核态之间数据拷贝的开销；



#### 03 共享内存

进程间通过虚拟内存，共享同一段物理内存，大大提高了进程间通信的速度；



#### 04 信号量

实现进程的互斥与同步；

P操作：信号量-1， 如果>=0 ，代表还有可以用的资源；

V操作：信号量+1，如果<=0, 代表有阻塞中的进程，唤醒然后执行，

初始化信号量为1，代表的是进程间的互斥，代表始终只有一个进程在运行，而如果初始化为0，就代表进程的执行顺序有要求，执行顺序出错就会阻塞；



#### 05 信号

异常情况下的进程间通信；

唯一的异步通信机制，可以在任何时候发送给某个进程；



#### 06 Socket（？？？）

跨网络与不同主机间通信；



### 4.11 多线程同步

#### 01 互斥

临界区：多线程操作可能导致竞争状态的一段代码，访问共享资源的代码片段，不能交给多线程执行；

互斥：保证共享资源在同一时间内只有一个线程能够访问；



#### 02 同步

并发进程或线程在一段时间内相互制约的等待与互通消息称之为，同步。



进程间互斥同步的实现：加锁或者信号量机制；



#### 03 锁

忙等待锁：利用自旋机制，如果获取不到锁，就一直等待；

无等待锁：利用队列，如果执行了unlock，队列中的第一个线程或进程就进入就绪状态，获取资源；



#### 04 信号量

P操作：小于零，插入等待队列；

V操作：小于等于0，将队首元素转换为就绪状态；



#### 05 生产者消费者问题

分析：同一时间只能取或者放，不能同时进行，也就是两者需要互斥，一个信号量为1，并且需要先放，然后才能获取，还需要一个信号量为0；

三个信号量：满，空，mutex；

生产者：

1. p空槽，代表空槽-1；
2. p（mutex），代表互斥；
3. 操作资源
4. v（mutex），解除互斥；
5. v满槽，代表增加一个满槽；

消费者：

1. p满槽，代表减少一个满槽；
2. p（mutex），代表互斥；
3. 操作资源
4. v（mutex），解除互斥；
5. v空槽，代表空槽+1；



### 4.12 同步问题



#### 4.13 死锁

死锁的四个条件：

- 互斥条件；
- 环路等待
- 不可剥夺
- 持有并等待条件；



#### 01 互斥条件

多个线程不能同时使用一个共享资源；



#### 02 持有等待条件

持有资源的同时，如果获取其他资源失败，并不会释放已经持有的资源；



#### 03 不可剥夺条件

线程持有资源在自己使用完以前不能被别的资源抢占；



#### 04 环路等待条件

两个线程获取资源的顺序形成了一个环；



### 4.13 避免死锁问题的发生

#### 01 资源的有序分配

有序分配资源，如果所有资源的分配顺序相同，就几乎不会出现死锁问题，也就是打破了环路等待的条件； 	







## 第五章 调度算法

### 5.1 进程调度

#### 01 先来先服务（FCFS）

先来的就一直运行到结束为止；

对IO频繁的系统并不友好， 可能会导致短作业一直等待；



#### 02 最短作业优先（SJF）

最短的作业总是排在最前面，

这种算法会导致长作业一直等待；



#### 03 高响应比优先

响应比：（等待时间+要求服务时间）/ 要求服务时间；

高响应比的事件总是排在前面；

#### 其余见4.10章节



### 5.2 页面置换算法

#### 01 缺页中断

当指令在CPU内存中找不到所需要的页的时候，触发一个缺页中断，到磁盘中去置换一个页；

而置换什么页就是接下来的页面置换算法；



#### 02 最佳页面置换算法

置换在未来最长时间不使用的页面；

但实际上无法实现；

#### 03 先进先出置换算法

最先进来的最先置换出去；

看似还行，但是实现比较麻烦，置换的代价高昂；



#### 04 时钟页面置换算法

环形链表，然后更新访问位，直到一个访问为0 的就淘汰，



#### 05 最不常用算法

发生缺页中断的时候，将访问次数最少的页面置换出去；



### 5.3 磁盘调度算法

#### 01 FCFS

先到的请求先服务；



#### 02 最短寻道时间优先算法

所有请求中需要磁头移动距离最短的先服务，

可能产生饥饿现象；



#### 03 扫描算法

在一个方向上扫描，到达该方向上最后一个请求，才会调换方向；



#### 04 循环扫描算法

只响应一个方向上的请求；到达一个方向上的最末端后才直接移到另一端，中途不处理任何事务；



#### 05 LOOK和C_LOOK算法

LOOK：到达一个方向的最后位置后，直接反向并处理；

C_LOOK：反向后不处理任何事务；



## 第六章 文件系统

每个文件有两个数据结构：

1. 索引节点：

   是文件的唯一标识，存储在硬盘中

2. 目录项：

   存储的是文件名和索引节点指针，存储在内存中；



目录也是文件，目录项是一个数据结构，保存在内存中；



### 6.1 文件存储在磁盘

磁盘读写的最小单位是扇区，系统把多个扇区组合成一个逻辑块，每次读写一个逻辑块；

磁盘格式化的时候会分成三个区块：

1. 超级块；

   存储的是文件系统的详细信息，快个数，空间大小，空闲块等等

2. 索引节点区

   存储索引节点，

3. 数据块区

   存储文件或目录数据；



### 6.2 虚拟文件系统

用户层和操作系统之间提供一个中间层，也就是提供操作文件系统的接口，就是所谓的虚拟文件系统；

文件系统的基本操作单位是：数据块；	



### 6.3 文件的存储

分为两种方式：

1. 连续空间存储；
2. 非连续空间存储；



#### 01 连续空间存储

读写效率高，存储在一段连续的物理空间上，一次扫描可以读写所有数据；



缺点：

- 磁盘空间碎片；
- 文件长度不易扩展；



#### 02 非连续空间存储

链表方式和索引方式；

- 链表分配方式：

  无外部碎片，动态增长十分方便；

  但是查找效率低下；

- 索引分配方式

  可以随即访问，易于文件的删改；

  影响文件系统的效率，而且创建索引会有开销；





### 6.4 空闲空间的管理

- 空闲表法；
- 空闲链表法；
- 位图法；



#### 01 空闲表法

为所有空闲空间建立一张表，表的内容包括第一个空闲数据块和空闲块的数量，

适用于一段连续的空闲数据块；

适用于少量空闲空间的时候，如果空闲空间太多，空闲表就会很大，导致查询效率低下；



#### 02 空闲链表法

可以用链表方式存储，只要找到第一个空闲区块，就可以找到后续所有的空闲区块；

特点是实现十分简单，但不能随机访问，工作效率低下；



#### 03 位图法

用二进制来表示一个磁盘中所有数据块的使用情况；0为空闲，1为使用中；



### 6.5 软链接和硬链接

#### 01 硬链接

多个目录项的索引节点指向同一个文件的inode，但硬链接不可能跨多个文件系统，因为每个文件系统有自己的独特的列表和数据结构，只有删除所有的硬链接和源文件才能够彻底删除该文件系统；

#### 02 软链接

软链接相当于不同的重新创建一个文件，该文件有自己独立的inod，只不过文件的内容指向了另一个文件的路径，目标文件被删除的时候，链接文件依然存在，只不过指向的文件找不到了；



### 6.6 文件的IO

#### 01 缓冲与非缓冲IO

缓冲与否就是看是否通过标准库的缓存来缓存了io信息；

有缓冲区就可以减少直接调用系统的次数，减少了CPU切换上下文的开销；



#### 02 直接与非直接IO

直接IO：直接通过文件系统与磁盘交互完成io，并不经过用户区到内核区的数据拷贝；



#### 03 阻塞/非阻塞，同步/异步IO

阻塞IO：发出指令后，阻塞，直到内核态的数据从缓冲区拷贝到用户态的缓冲区；

非阻塞IO：发出指令后，等待内核态数据准备好并拷贝到用户态的缓冲区的期间，不断地轮询，期间继续执行；

IO多路复用，以上三种都是同步调用，需要等待处理数据；

异步调用并不需要等待；



IO的两个过程：

1. 内核态准备数据；
2. 数据从内核态缓冲区拷贝到用户态缓冲区；





## 第七章 设备管理

### 7.1 设备控制器

设备控制器会根据不同的设备进行分类，并通过控制器来管理这些设备，控制器一共有三类寄存器：

1. 状态寄存器；
2. 命令寄存器；
3. 数据寄存器；



输入输出设备的分类：

1. 块设备：数据存储在固定的块中，每个块有自己的地址；
2. 字符设备：以字符为单位发送或接收字符；



不管如何使用，设备都是在缓冲区存够了以后，才会发送数据；



### 7.2 IO控制方式

通知CPU的方式：

1. 轮询等待，CPU一直查询寄存器的状态，
2. 中断：硬件的中断控制器，设备任务完成后就发出一个中断，
3. DMA功能，数据不通过CPU直接写入数据；再写入完毕后，给CPU发中断消息，让CPU直接调用数据。



### 7.3 设备驱动程序

属于操作系统内核， 可以直接调用操作系统的代码，设备驱动程序会提供统一的接口，不同的设备驱动程序，以相同的方式接入操作系统；

中断处理程序的处理流程：

1. 发送CPU一个中断请求；
2. 保护被中断程序的上下文（寄存器，程序计数器）；
3. 调用中断处理函数；
4. 进行中断处理；
5. 恢复上下文；



### 7.4 通用块层

linux系统为减少不同块设备之间的差异，直接提供一个统一的通用块层，有两个功能，向上为文件系统和应用程序提供一个统一的访问接口，向下把各种不同的磁盘设备抽象为统一的块设备，并在内核层面提供一个统一的框架来管理；

第二个功能是为应用程序和文件系统发来的IO请求排序，设计了五种IO请求排序算法：

1. 没有调度算法（虚拟机专用）；
2. 先来先服务；
3. 完全公平（使用最多）；
4. 优先级调度算法；
5. 最终期限调度算法；



### 7.5 存储系统IO软件分层

1. 文件系统层：

   包括虚拟文件系统和其他文件系统的实现，向上应用程序提供了统一的接口，向下通过通用块层存储和管理磁盘数据；

2. 通用块层

   包括设备的IO队列和IO调度器，对文件系统的IO进行排队，通过IO调度器，将请求 发送给下一层；

3. 设备层

   包括硬件设备，设备控制器，和硬件驱动程序，负责最终物理设备的IO处理；



存储系统的IO是整个系统最慢的环节，所以操作系统提供了很多缓存机制来提高IO效率

- 提高文件的读写效率，引入了页缓存，索引节点缓存，目录项缓存等多个
- 为了提高块设备的访问效率，引入了块设备的缓冲区；



## 第八章 网络系统

### 8.1 网络模型

七层OSI：

四层TCP/IP：

- 应用层
- 传输层
- 网络层
- 网络接口层



### 8.2 Linux接收网络包的流程

NAPI方式：

​	不通过中断来获取数据，而是没接收到一个网络包，触发中断，然后调用接收数据的程序，然后用poll的方式来轮询数据，这样的好处是一次中断处理多个网络包，降低网卡中断带来的性能开销；

1. 网卡读入数据，不合法则丢弃；
2. 传入到网络层，去IP头
3. 传输层去TCP头
4. 根据四元组找到对应的socket，应用层读取到socket缓冲区；
5. 调用socket接口，从内核的缓冲区读取到应用层；





### 8.3 零拷贝

#### 01 DMA技术

直接内存访问技术

数据搬运全部交给DMA控制器；

过程：

- 用户调用read方法，发送请求给CPU， 操作系统收到请求，将请求发给DMA控制器，然后CPU执行其他任务；
- DMA收到请求后，让磁盘将数据拷贝到磁盘缓冲区；
- 数据拷贝完成后，DMA会收到磁盘的请求，此时DMA直接将磁盘缓冲区中的数据拷贝到内存缓冲区中，DMA读到了足够多的数据，给CPU发送信号；
- CPU收到DMA发送的信号后，直接将内核数据拷贝到用户态，并返回系统调用；



#### 02 优化文件传输效率

1. 减少CPU上下文转换的次数：

   每次系统调用至少两次上下文切换，因为从用户态转为内核态，再从内核态转为用户态，所以减少系统调用；

2. 减少数据拷贝的次数

   用户的缓存区并没有必要存在，因为并不会处理数据；



#### 03 实现零拷贝

1. mmap + write

   mmap直接把内核态的数据映射到用户空间，内核与用户空间就不需要任何的拷贝操作；

   write过程直接将内核缓冲区的数据拷贝到socket缓冲区中，发生在内核态，不需要拷贝，最后由内核搬运到网卡缓冲区，由DMA完成；

   任然调用了两次CPU还是需要四次上下文切换；

2. sendfile

### 8.4 PageCache

所谓的内核缓冲区，也即是磁盘高速缓存；

两个优点：

1. 缓存最近被访问的数据；
2. 预读功能；

注意：大文件不因该使用零拷贝和PageCache；因为这样会导致热点小文件无法很快读取，在高并发环境中非常致命；

大文件的传输：

使用异步IO+直接IO，也就是不适用PageCache的IO，直接拷贝到用户进程；



### 8.5 多路IO复用

#### 01 socket模型

每个socket维护两个队列：

1. 半连接 队列；
2. 全连接队列；



### 8.6 

### 





